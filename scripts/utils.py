import os, sys, shutil, json, random, multiprocessing, re
import pandas as pd
import numpy as np
from functools import partial
from PIL import Image
from pathlib import Path

from scripts.params import *
from scripts.matrix_function import *
from scripts.reax_ff_data import bo

import logging
from scripts.logging import setup_logging
setup_logging()
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


with open('scripts/test_indices.json', 'r') as f:
    test_indices = json.load(f)

qm7_val = test_indices['qm7_val']
qm8_val = test_indices['qm8_val']
qm9_val = test_indices['qm9_val']
#qm9_2_val = test_indices['qm9_2_val']
#qm9_3_val = test_indices['qm9_3_val']
#qm9_4_val = test_indices['qm9_4_val']
#qm9_6_val = test_indices['qm9_6_val']
#qm9_32_val = test_indices['qm9_32_val']

qm9_train = test_indices['qm9_train']
qm9_2_train = test_indices['qm9_2_train']
qm9_3_train = test_indices['qm9_3_train']
qm9_4_train = test_indices['qm9_4_train']
qm9_6_train = test_indices['qm9_6_train']

def get_list_of_files():
    '''Get the list of all .xyz file available, if directory is empty then exctract information from .tar file'''
    try:
        files = os.listdir(f'{PATH}/data')
    except FileNotFoundError:
        os.system('mkdir data')
        os.system(f'tar -xvf dsgdb9nsd.xyz.tar.bz2 -C {PATH}/data')
        files = os.listdir(f'{PATH}/data')

    return files

r_range, g_range, b_range = (0,1),(0,1),(0,1)
def scale_rgb_values(r, g, b):
    global r_range, g_range, b_range

    r = (255 * (r - r_range[0]) / (r_range[1] - r_range[0])).astype(int)
    g = (255 * (g - g_range[0]) / (g_range[1] - g_range[0])).astype(int)
    b = (255 * (b - b_range[0]) / (b_range[1] - b_range[0])).astype(int)
    return r, g, b

def calibration(ds, STEP, bo):

    '''A function that checks whether the matrices generated 
    on the entered settings contain values in the range 0-255

    '''
    ds = pd.read_csv(f'{PATH}/{DB}.csv')
    global r_range, g_range, b_range
    data = []
    start = random.randint(0,5) #to avoid too long execution
    for compound in range(start, len(ds), STEP): #step != 1 to avoid too long execution
        data.append(making_rgb_numerically(compound, bo, ds, scaling=False))
        print(f'\rCalibration: {100*compound/len(ds):.2f}%', end='')

    max_values = []
    min_values = []

    for matrices_group in zip(*data):
      max_group = np.max([np.max(matrix) for matrix in matrices_group])
      min_group = np.min([np.min(matrix) for matrix in matrices_group])
      max_values.append(max_group)
      min_values.append(min_group)

    logging.info(f"\nr_range= {min_values[0]:.2f}, {max_values[0]:.2f}")
    logging.info(f"g_range= {min_values[1]:.2f}, {max_values[1]:.2f}")
    logging.info(f"b_range= {min_values[2]:.2f}, {max_values[2]:.2f}")
    return (min_values[0],max_values[0]),(min_values[1],max_values[1]),(min_values[2],max_values[2])

def making_rgb_numerically(row, bo, ds, scaling=SCALING, verbose = False, image_type = TYPE_OF_IMAGE, RANDOM_OR=RANDOM_OR, MARGIN=MARGIN):
    '''function that, based on a single row in the database, creates three 
    MATRIX_SIZExMATRIX_SIZE matrices that contain numerical data generated by 
    various functions contained in the file matrix_function.py'''

    cords = eval(ds.cords.iloc[row])
    n_atoms = ds.n_atoms.iloc[row]
    atom_types = eval(ds.atom_type.iloc[row])
    logging.debug(f"Making matrices for {ds.ID.iloc[row]} compound")
    
    if image_type == 'A':
        r = distance(cords, n_atoms)
        r += ionization(atom_types, n_atoms)

        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
        b = (bond_order(distance(cords, n_atoms), atom_types, bo))

    elif image_type == 'B':
        r = distance(cords, n_atoms)
        r += ionization(atom_types, n_atoms)

        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = True)
        b = (bond_order(distance(cords, n_atoms), atom_types, bo))

    elif image_type == 'C':
        r = distance(cords, n_atoms)
        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
        b = (bond_order(distance(cords, n_atoms), atom_types, bo))

    elif image_type == 'D':
        r = distance(cords, n_atoms)

        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
        b = (atomic_charge(atom_types, n_atoms))
        b += (bond_order(distance(cords, n_atoms), atom_types, bo))

    elif image_type == 'E':
        r = ionization(atom_types, n_atoms)
        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = True)
        b = (atomic_charge(atom_types, n_atoms))

    elif image_type == 'F':
        r = distance(cords, n_atoms)
        r += ionization(atom_types, n_atoms)

        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = True)
        b = (atomic_charge(atom_types, n_atoms))

    elif image_type == 'G':
        r = distance(cords, n_atoms)

        g = mulliken(eval(ds.mulliken.iloc[row]), n_atoms)
        g += coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
    
        b = (atomic_charge(atom_types, n_atoms))
        b += (bond_order(distance(cords, n_atoms), atom_types, bo))

    elif image_type == 'H':
        r = distance(cords, n_atoms)
        r += ionization(atom_types, n_atoms)

        g = mulliken(eval(ds.mulliken.iloc[row]), n_atoms)
        g += coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
    
        b = (atomic_charge(atom_types, n_atoms))
        b += (bond_order(distance(cords, n_atoms), atom_types, bo))
    elif image_type == 'PC':
        r = distance(cords, n_atoms)
        g = coulomb_matrix(cords, n_atoms, atom_types, diagonal = False)
        b = atomic_charge(atom_types, n_atoms)

    if scaling:
        r,g,b = scale_rgb_values(r,g,b) 

    #pasting the matrix into larger black matrix in random way		
    if RANDOM_OR == True: 
        init_cords = (random.randint(0,MATRIX_SIZE-n_atoms), random.randint(0,MATRIX_SIZE-n_atoms)) 
    else: 
        init_cords = (0,0)

    if MARGIN == 'black':
        value_r, value_g, value_b=0,0,0
    elif MARGIN=='white':
        value_r, value_g, value_b=255,255,255 #calibration does not work well
    elif MARGIN=='avg':
        value_r, value_g, value_b = np.mean(r), np.mean(g), np.mean(b)
    
    if MATRIX_SIZE != 0:
        final_r = np.full((MATRIX_SIZE, MATRIX_SIZE), value_r)
        final_g = np.full((MATRIX_SIZE, MATRIX_SIZE), value_g)
        final_b = np.full((MATRIX_SIZE, MATRIX_SIZE), value_b)

        final_r[init_cords[0]:init_cords[0] + n_atoms, init_cords[1]:init_cords[1] + n_atoms] = r
        final_g[init_cords[0]:init_cords[0] + n_atoms, init_cords[1]:init_cords[1] + n_atoms] = g
        final_b[init_cords[0]:init_cords[0] + n_atoms, init_cords[1]:init_cords[1] + n_atoms] = b

        return final_r, final_g, final_b
    return r,g,b

def making_rgb(mat, id, label):
  ''' Function that takes the result of the making_rgb_numerically function and transforms the set of three matrices into a finished png image'''
  combined = np.transpose(np.array((mat[0],mat[1],mat[2])),(1,2,0))

  img = np.array(combined, dtype=np.uint8)
  pImg = Image.fromarray(img, mode='RGB')
  #print(f"{PATH}/{label}/{id}.png")
  pImg.save(f"{PATH}/{label}/{id}.png")
  print(f"\r {id} have been saved in {label} directory", end='')

def process_image(chem, bo, ds, split):

    #test set
    if DB == 'qm7_demo':
        test_set = qm7_val
    elif DB == 'qm8_demo':
        test_set = qm8_val
    elif DB.split('_')[0] == 'qm9':
        test_set = qm9_val
    elif DB.split('_')[0] == 'pc':
        test_set = ['82', '19906', '95', '19341', '4b-met', '20', '551', '8019', '91092', '478', '1-met', '35340', '61881', '9849', '23180', '39127', '2-pin-pos-1', '27', '6-met', '10', '28009', '59169',
 '337', '57826', '14722', '27563', '9619', '6527', '44959', '16400', '733', '2446', '7553', '463', '3621', '6954', '1062',
 '1902', '455', '185', '8490', '72183', '107987', '22806', '15360', '5075', '27420', '4', '33645', '691', '1109', '23', '03-PNP-iPr-iPr', '62176', '311',
 '460', '7787', '279', '1255', '5621']
    
    elif DB.split('_')[0] == 'omol' or DB.split('_')[0] == 'tg':
        # The original line is incorrect. It tries to access the second element of the result of .str.split('_'), but this returns a Series of lists, not a DataFrame with columns.
        # The correct way is to split the 'ID' column, extract the second part for each row, and get the list of those values.
        
        test_set = ds.sample(frac=0.1)['ID'].str.split('_').str[1].tolist() #very bad approach, each time we generate image, we get a different test set
        print('Every time we generate image, we get a different test set!!!!')
    else:
        test_set = []

    #train set
    if DB == 'qm9_2':
        train_set = qm9_2_train
    elif DB == 'qm9_3':
        train_set = qm9_3_train
    elif DB == 'qm9_4':
        train_set = qm9_4_train
    elif DB == 'qm9_6':
        train_set = qm9_6_train
    elif DB == 'qm9':
        train_set = qm9_train
    elif DB.split('_')[0] == 'qm7':
        train_set = [x for x in range(3993) if x not in test_set]
    elif DB.split('_')[0] == 'pc':
        train_set = ['2292', '54', '3488', '4559', '95216', '2455', '27002', '560', '9166', '4178', '41408', '172', '9371', '7085', '76078', '63443', '834', '6992', '10893', '43308', '3752', '124', '623', '12423', '73171', '25559', '48', '5013', '1177', '108', '26466', '101745', '1183', '1730', '84', '535', '86007', '13919', '143', '67774', '403', '147', '541', '9', '44048', '4456', '102', '120', '844', '46926', '205', '570', '33611', '57280', '500', '685', '13', '67853', '3888', '2652', '226', '68404', '19992', '2300', '22', '48061', '363', '4468', '2543', '317', '73', '232', '123', '66952', '5562', '71190', '33', '1514', '15', '354', '14429', '737', '64', '51635', '19354', '33608', '2661', '3261', '371', '825', '45', '3020', '152', '11659', '129433', '81895', '69531', '1021', '6298', '6943', '91929', '32613', '6369', '38', '4931', '69722', '39314', '78', '162', '1311', '20246', '19203', '6900', '70992', '911', '23451', '116', '112740', '102722', '20998', '1201', '5802', '11115', '3149', '24882', '40730', '8221', '101933', '37728', '513', '87187', '191', '19649', '13493', '183', '2298', '24011', '24633', '610', '4236', '48312', '135', '164', '18066', '160', '1053', '27539', '104295', '14805', '69', '100582', '3', '13591', '44', '5040', '1532', '28907', '111', '756', '5047', '43', '4002', '89643', '132459', '4446', '26765', '6171', '51204', '291', '9713', '891', '2657', '47942', '496', '32296', '1218', '42182', '1438', '8356', '842', '117821', '58', '632', '4759', '1415', '1330', '130497', '61435', '1533', '79540', '1299', '13072', '1510', '224', '127', '6680', '8205', '2314', '61', '7148', '41', '18360', '23177', '8129', '1553', '106', '3239', '69848', '189', '20774', '51142', '86742', '487', '1799', '38549', '12871', '3596', '72623', '553', '7390', '52', '22044', '4255', '16775', '88553', '5955', '79', '17', '40', '123273', '4876', '453', '392', '3098', '1457', '15236', '23018', '97535', '10626', '1705', '77704', '25092', '1061', '39536', '6642', '1306', '504', '50839', '99', '1233', '35796', '13259', '10373', '1298', '6095', '44031', '21', '3128', '9799', '1186', '54106', '7', '81691', '200', '29616', '2550', '23833', '196', '810', '494', '94958', '6048', '32804', '674', '176', '324', '958', '755', '1499', '19342', '251', '14308', '119835', '900', '8399', '68', '28736', '20736', '10584', '68094', '28', '1122', '46457', '75', '104936', '1396', '31', '70570', '380', '7623', '13322', '28750', '84028', '648', '9938', '12580', '29736', '1140', '59', '5871', '2632', '118', '20500', '3130', '1435', '161', '3226', '132', '80', '11632', '1764', '2937', '274', '16504', '464', '14137', '430', '41113', '329', '1035', '11569', '5568', '2057', '50977', '59003', '473', '990', '32', '310', '4553', '104081', '11522', '118812', '37', '5', '1551', '91736', '12485', '21510', '16098', '25574', '1952', '95879', '10340', '6363', '1524', '44588', '109', '524', '42839', '750', '3012', '433', '26001', '86355', '1380', '522', '4383', '73943', '126184', '91330', '309', '7101', '12250', '6453', '1698', '36912', '6360', '88829', '36106', '114', '129', '1462', '20252', '849', '8519', '84397', '6742', '931', '17149', '38610', '17453', '107199', '749', '2837', '41985', '13879', '44604', '1719', '10276', '2806', '331', '128506', '5366', '36965', '7651', '30692', '9063', '6', '26400', '1421', '14', '2051', '131917', '64045', '5504', '17456', '43927', '5210', '40655', '7706', '15554', '57024', '1723', '125169', '2307', '179', '18005', '2864', '79402', '2553', '806', '425', '8469', '356', '81946', '83', '15905', '124655', '8783', '146', '29872', '81', '37154', '2913', '873', '4460', '2995', '7174', '102971', '10648', '1040', '24129', '62560', '50406', '173', '18', '3706', '13438', '39386', '15191', '99002', '4615', '8120', '39', '14988', '55598', '343', '16217', '2134', '6021', '9543', '30644', '37031', '10896', '614', '15380', '3572', '19328', '1098', '60', '57706', '5812', '66', '895', '22540', '407', '3931', '735', '12236', '912', '6153', '4058', '15287', '17273', '1', '8563', '9852', '423', '2776', '511', '2903', '757', '2', '615', '86', '333', '150', '53', '1739', '40673', '54951', '93030', '962', '2321', '108891', '5114', '11776', '5373', '7-pin-co2-pos-1', '17-vas', '04-PNP-tBu-tBu', '7-vas', '02-PNN-tBu-Et', '6-pin-pos-1', '13-met', '20-vas', '4-met', '8-pin-co2-pos-1', '5-pin-co2-pos-1', '3-pin-cis', '12-vas', '10-met', '22-vas', '14-met', '01-PNP-tBu', '13opt-co', '27-vas', '3-pin']
    elif DB.split('_')[0] == 'omol' or DB.split('_')[0] == 'tg':
        print('Every time we generate image, we get a different test set!!!!')
        train_set = [str(x) for x in range(len(ds)) if str(x) not in test_set]
    else:
        train_set = ds.ID.tolist()

    train_set = [str(x) for x in train_set]
    test_set = [str(x) for x in test_set]
    
    #print(f"train len {len(train_set)}, train_set[:10]")
    #print(f"test len {len(test_set)}, test_set[:10]")
    #print(f"Sum of train and test {len(test_set+train_set)}")
    #print(f"Number of unique compounds in db {len(list(set(test_set+train_set)))}")
    if ds.ID.iloc[chem].split('_')[1] in test_set:
        making_rgb(making_rgb_numerically(chem, bo, ds), ds.ID.iloc[chem], label=TEST_DIR_NAME)
    elif ds.ID.iloc[chem].split('_')[1] in train_set:
        making_rgb(making_rgb_numerically(chem, bo, ds), ds.ID.iloc[chem], label=TRAIN_DIR_NAME)

def creating_images(start, end, bo, ds, STEP, split=0.1):
    #print(f'Creating {end-start+1} images for training model')
    print(f'Rearranging train and test files')
    
    try:
        shutil.rmtree(f'{PATH}/{TRAIN_DIR_NAME}')
        os.makedirs(f'{PATH}/{TRAIN_DIR_NAME}', exist_ok=True)
    except FileNotFoundError:
        os.makedirs(f'{PATH}/{TRAIN_DIR_NAME}', exist_ok=True)

    try:
        shutil.rmtree(f'{PATH}/{TEST_DIR_NAME}')
        os.makedirs(f'{PATH}/{TEST_DIR_NAME}', exist_ok=True)
    except FileNotFoundError:
        os.makedirs(f'{PATH}/{TEST_DIR_NAME}', exist_ok=True)
    
    if SCALING==True:
        global r_range, g_range, b_range
        print(f'Calibration for each spectra (based on {len(ds)/STEP/len(ds)*100:.2f}% of data):')
        r_range, g_range, b_range = calibration(ds,STEP,bo)
    
    print(f'\nCreating images, this process may take a lot of time')

    if MULTIPROCESS:
        process_image_partial = partial(process_image, bo=bo, ds=ds, split=split)

        #multiprocessing
        print(f'Running with multiprocessing using {NUM_PROC} processes')
        with multiprocessing.Pool(processes=NUM_PROC) as pool:
            pool.map(process_image_partial, range(start, end+1))
    else:
        #singleprocessing
        print('Running without multiprocessing')
        for chem in range(start, end+1):
            print(f"\r{chem}/{end+1}",end='')
            process_image(chem, bo=bo, ds=ds, split=split)
    print(f'Creating images have been finished. There are {len(os.listdir(f'{PATH}/{TRAIN_DIR_NAME}'))} files in {TRAIN_DIR_NAME} directory and {len(os.listdir(f'{PATH}/{TEST_DIR_NAME}'))} in {TEST_DIR_NAME} directory.')

def modify_params(changes):
    '''Function which modify params in scripts/params.py file
    Changes is a directory with new values of param e.g. {'CYCLE':4}'''
    with open('scripts/params.py', 'r') as file:
        content = file.read()

    for param, value in changes.items():
        if isinstance(value, str):
            value = f"'{value}'"
        content = re.sub(f'{param} = .*', f'{param} = {value}', content)


    with open('scripts/params.py', 'w') as file:
        file.write(content)
